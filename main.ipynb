{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmagcaya/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:513: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.object,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/tmagcaya/work/MotionPPGNet/main.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tmagcaya/work/MotionPPGNet/main.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tmagcaya/work/MotionPPGNet/main.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Import model libs\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tmagcaya/work/MotionPPGNet/main.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tmagcaya/work/MotionPPGNet/main.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, Conv1D, Dropout, Flatten, MaxPooling1D, BatchNormalization, LSTM\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tmagcaya/work/MotionPPGNet/main.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizers\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/keras/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m _tf_keras\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/keras/_tf_keras/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tf_keras\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/keras/_tf_keras/keras/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/keras/activations/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m get\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m serialize\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/keras/src/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/keras/src/activations/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtypes\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m elu\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m exponential\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m gelu\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/keras/src/activations/activations.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/keras/src/backend/__init__.py:33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m# Import backend functions.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m backend() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39melif\u001b[39;00m backend() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjax\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mjax\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/keras/src/backend/tensorflow/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m distribution_lib\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m image\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/keras/src/backend/tensorflow/core.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtypes\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompiler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf2xla\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxla\u001b[39;00m \u001b[39mimport\u001b[39;00m dynamic_update_slice\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m \u001b[39mimport\u001b[39;00m KerasVariable\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/__init__.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_six\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     44\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/__init__.py:46\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     43\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n\u001b[1;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/data/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m     24\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m AUTOTUNE\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/data/experimental/__init__.py:96\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m     95\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m \u001b[39mimport\u001b[39;00m service\n\u001b[1;32m     97\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatching\u001b[39;00m \u001b[39mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[1;32m     98\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatching\u001b[39;00m \u001b[39mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/data/experimental/service/__init__.py:140\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m division\n\u001b[1;32m    138\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m--> 140\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_service_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m    141\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_service_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m from_dataset_id\n\u001b[1;32m    142\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_service_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m register_dataset\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m compression_ops\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute_options\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoShardPolicy\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute_options\u001b[39;00m \u001b[39mimport\u001b[39;00m ExternalStatePolicy\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/compression_ops.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m division\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m structure\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[39mas\u001b[39;00m ged_ops\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompress\u001b[39m(element):\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/data/util/structure.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwrapt\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m nest\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m composite_tensor\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/data/util/nest.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_six\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_utils\n\u001b[0;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m sparse_tensor \u001b[39mas\u001b[39;00m _sparse_tensor\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m collections_abc \u001b[39mas\u001b[39;00m _collections_abc\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sorted\u001b[39m(dict_):\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/framework/sparse_tensor.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m composite_tensor\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m constant_op\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m execute\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m op_callbacks\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:513\u001b[0m\n\u001b[1;32m    482\u001b[0m     _NP_TO_TF[pdt] \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\n\u001b[1;32m    483\u001b[0m         _NP_TO_TF[dt] \u001b[39mfor\u001b[39;00m dt \u001b[39min\u001b[39;00m _NP_TO_TF \u001b[39mif\u001b[39;00m dt \u001b[39m==\u001b[39m pdt()\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    486\u001b[0m TF_VALUE_DTYPES \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(_NP_TO_TF\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    489\u001b[0m _TF_TO_NP \u001b[39m=\u001b[39m {\n\u001b[1;32m    490\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_HALF:\n\u001b[1;32m    491\u001b[0m         np\u001b[39m.\u001b[39mfloat16,\n\u001b[1;32m    492\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_FLOAT:\n\u001b[1;32m    493\u001b[0m         np\u001b[39m.\u001b[39mfloat32,\n\u001b[1;32m    494\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_DOUBLE:\n\u001b[1;32m    495\u001b[0m         np\u001b[39m.\u001b[39mfloat64,\n\u001b[1;32m    496\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT32:\n\u001b[1;32m    497\u001b[0m         np\u001b[39m.\u001b[39mint32,\n\u001b[1;32m    498\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT8:\n\u001b[1;32m    499\u001b[0m         np\u001b[39m.\u001b[39muint8,\n\u001b[1;32m    500\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT16:\n\u001b[1;32m    501\u001b[0m         np\u001b[39m.\u001b[39muint16,\n\u001b[1;32m    502\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT32:\n\u001b[1;32m    503\u001b[0m         np\u001b[39m.\u001b[39muint32,\n\u001b[1;32m    504\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT64:\n\u001b[1;32m    505\u001b[0m         np\u001b[39m.\u001b[39muint64,\n\u001b[1;32m    506\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT16:\n\u001b[1;32m    507\u001b[0m         np\u001b[39m.\u001b[39mint16,\n\u001b[1;32m    508\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT8:\n\u001b[1;32m    509\u001b[0m         np\u001b[39m.\u001b[39mint8,\n\u001b[1;32m    510\u001b[0m     \u001b[39m# NOTE(touts): For strings we use np.object as it supports variable length\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[39m# strings.\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_STRING:\n\u001b[0;32m--> 513\u001b[0m         np\u001b[39m.\u001b[39;49mobject,\n\u001b[1;32m    514\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_COMPLEX64:\n\u001b[1;32m    515\u001b[0m         np\u001b[39m.\u001b[39mcomplex64,\n\u001b[1;32m    516\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_COMPLEX128:\n\u001b[1;32m    517\u001b[0m         np\u001b[39m.\u001b[39mcomplex128,\n\u001b[1;32m    518\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT64:\n\u001b[1;32m    519\u001b[0m         np\u001b[39m.\u001b[39mint64,\n\u001b[1;32m    520\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_BOOL:\n\u001b[1;32m    521\u001b[0m         np\u001b[39m.\u001b[39mbool,\n\u001b[1;32m    522\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QINT8:\n\u001b[1;32m    523\u001b[0m         _np_qint8,\n\u001b[1;32m    524\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QUINT8:\n\u001b[1;32m    525\u001b[0m         _np_quint8,\n\u001b[1;32m    526\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QINT16:\n\u001b[1;32m    527\u001b[0m         _np_qint16,\n\u001b[1;32m    528\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QUINT16:\n\u001b[1;32m    529\u001b[0m         _np_quint16,\n\u001b[1;32m    530\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QINT32:\n\u001b[1;32m    531\u001b[0m         _np_qint32,\n\u001b[1;32m    532\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_BFLOAT16:\n\u001b[1;32m    533\u001b[0m         _np_bfloat16,\n\u001b[1;32m    534\u001b[0m \n\u001b[1;32m    535\u001b[0m     \u001b[39m# Ref types\u001b[39;00m\n\u001b[1;32m    536\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_HALF_REF:\n\u001b[1;32m    537\u001b[0m         np\u001b[39m.\u001b[39mfloat16,\n\u001b[1;32m    538\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_FLOAT_REF:\n\u001b[1;32m    539\u001b[0m         np\u001b[39m.\u001b[39mfloat32,\n\u001b[1;32m    540\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_DOUBLE_REF:\n\u001b[1;32m    541\u001b[0m         np\u001b[39m.\u001b[39mfloat64,\n\u001b[1;32m    542\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT32_REF:\n\u001b[1;32m    543\u001b[0m         np\u001b[39m.\u001b[39mint32,\n\u001b[1;32m    544\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT32_REF:\n\u001b[1;32m    545\u001b[0m         np\u001b[39m.\u001b[39muint32,\n\u001b[1;32m    546\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT8_REF:\n\u001b[1;32m    547\u001b[0m         np\u001b[39m.\u001b[39muint8,\n\u001b[1;32m    548\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT16_REF:\n\u001b[1;32m    549\u001b[0m         np\u001b[39m.\u001b[39muint16,\n\u001b[1;32m    550\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT16_REF:\n\u001b[1;32m    551\u001b[0m         np\u001b[39m.\u001b[39mint16,\n\u001b[1;32m    552\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT8_REF:\n\u001b[1;32m    553\u001b[0m         np\u001b[39m.\u001b[39mint8,\n\u001b[1;32m    554\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_STRING_REF:\n\u001b[1;32m    555\u001b[0m         np\u001b[39m.\u001b[39mobject,\n\u001b[1;32m    556\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_COMPLEX64_REF:\n\u001b[1;32m    557\u001b[0m         np\u001b[39m.\u001b[39mcomplex64,\n\u001b[1;32m    558\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_COMPLEX128_REF:\n\u001b[1;32m    559\u001b[0m         np\u001b[39m.\u001b[39mcomplex128,\n\u001b[1;32m    560\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT64_REF:\n\u001b[1;32m    561\u001b[0m         np\u001b[39m.\u001b[39mint64,\n\u001b[1;32m    562\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT64_REF:\n\u001b[1;32m    563\u001b[0m         np\u001b[39m.\u001b[39muint64,\n\u001b[1;32m    564\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_BOOL_REF:\n\u001b[1;32m    565\u001b[0m         np\u001b[39m.\u001b[39mbool,\n\u001b[1;32m    566\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QINT8_REF:\n\u001b[1;32m    567\u001b[0m         _np_qint8,\n\u001b[1;32m    568\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QUINT8_REF:\n\u001b[1;32m    569\u001b[0m         _np_quint8,\n\u001b[1;32m    570\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QINT16_REF:\n\u001b[1;32m    571\u001b[0m         _np_qint16,\n\u001b[1;32m    572\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QUINT16_REF:\n\u001b[1;32m    573\u001b[0m         _np_quint16,\n\u001b[1;32m    574\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QINT32_REF:\n\u001b[1;32m    575\u001b[0m         _np_qint32,\n\u001b[1;32m    576\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_BFLOAT16_REF:\n\u001b[1;32m    577\u001b[0m         _np_bfloat16,\n\u001b[1;32m    578\u001b[0m }\n\u001b[1;32m    580\u001b[0m _QUANTIZED_DTYPES_NO_REF \u001b[39m=\u001b[39m \u001b[39mfrozenset\u001b[39m([qint8, quint8, qint16, quint16, qint32])\n\u001b[1;32m    581\u001b[0m _QUANTIZED_DTYPES_REF \u001b[39m=\u001b[39m \u001b[39mfrozenset\u001b[39m(\n\u001b[1;32m    582\u001b[0m     [qint8_ref, quint8_ref, qint16_ref, quint16_ref, qint32_ref])\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import time\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import model libs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Dropout, Flatten, MaxPooling1D, BatchNormalization, LSTM\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "\n",
    "fs = 125\n",
    "minBPM = 40\n",
    "maxBPM = 240\n",
    "window_length = 8 * fs\n",
    "window_shift = 2 * fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve dataset files\n",
    "data_fls, ref_fls = LoadTroikaDataset()\n",
    "errs, confs = [], []\n",
    "\n",
    "data_fl = data_fls[0]\n",
    "ref_fl = ref_fls[0]\n",
    "\n",
    "# load data using LoadTroikaDataFile\n",
    "ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "\n",
    "# bandpass filter the signals\n",
    "ppg = bandpass_filter(ppg, fs)\n",
    "accx = bandpass_filter(accx, fs)\n",
    "accy = bandpass_filter(accy, fs)\n",
    "accz = bandpass_filter(accz, fs)\n",
    "\n",
    "# Consider only magnitude of acceleration\n",
    "acc = calculate_magnitude(accx, accy, accz)\n",
    "\n",
    "# Standardization\n",
    "ppg = (ppg- np.mean(ppg))/np.std(ppg)\n",
    "acc = (acc- np.mean(acc))/np.std(acc)\n",
    "\n",
    "# loading the reference file\n",
    "ground_truth = sp.io.loadmat(ref_fl)['BPM0'].reshape(-1)\n",
    "\n",
    "X1 = []\n",
    "y1 = ground_truth\n",
    "for i in range(0, len(ppg) - window_length + 1, window_shift):\n",
    "\n",
    "    # aggregate accelerometer data into single signal to get the acc window\n",
    "    ppg_window = ppg[i:i+window_length]\n",
    "    acc_window = acc[i:i+window_length]\n",
    "\n",
    "    X1.append(ppg_window)\n",
    "\n",
    "\n",
    "X1 = np.array(X1)\n",
    "print(X1.shape)\n",
    "print(y1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "y = np.array(y)\n",
    "\n",
    "print(data_fls)\n",
    "for i in range(len(data_fls)):\n",
    "\n",
    "    data_fl = data_fls[i]\n",
    "    ref_fl = ref_fls[i]\n",
    "    # load data using LoadTroikaDataFile\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "\n",
    "    # bandpass filter the signals\n",
    "    ppg = bandpass_filter(ppg, fs)\n",
    "    accx = bandpass_filter(accx, fs)\n",
    "    accy = bandpass_filter(accy, fs)\n",
    "    accz = bandpass_filter(accz, fs)\n",
    "\n",
    "    # Consider only magnitude of acceleration\n",
    "    acc = calculate_magnitude(accx, accy, accz)\n",
    "\n",
    "    # Standardization\n",
    "    ppg = (ppg- np.mean(ppg))/np.std(ppg)\n",
    "    acc = (acc- np.mean(acc))/np.std(acc)\n",
    "\n",
    "    # loading the reference file\n",
    "    ground_truth = sp.io.loadmat(ref_fl)['BPM0'].reshape(-1)\n",
    "    y = np.append(y, ground_truth)\n",
    "\n",
    "    for i in range(0, len(ppg) - window_length + 1, window_shift):\n",
    "\n",
    "        # aggregate accelerometer data into single signal to get the acc window\n",
    "        ppg_window = ppg[i:i+window_length]\n",
    "        acc_window = acc[i:i+window_length]\n",
    "\n",
    "        X.append(ppg_window)\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model and evaluate\n",
    "seed = 42\n",
    "def split(X, y):\n",
    "    train_size = 0.8\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, random_state=seed)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = split(X, y)\n",
    "\n",
    "# TODO: Check if any of these change the data in any way\n",
    "# Reshaping the array to 3-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 1000, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1000, 1)\n",
    "X = X.reshape(X.shape[0], 1000, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "X = X.astype('float32')\n",
    "\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "# y = to_categorical(y)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of segments in x_train', x_train.shape[0])\n",
    "print('Number of segments in x_test', x_test.shape[0])\n",
    "\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model (trainX, trainy, testX, testy):\n",
    "trainX, trainy, testX, testy = x_train, y_train, x_test, y_test\n",
    "verbose, epochs, batch_size = 1, 1000, 25 # Batch size used to be 32\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[1], 1, 1\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=40, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filters=32, kernel_size=40, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "oldtime = time.time()\n",
    "model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "print(\"training time:\")\n",
    "print(time.time()-oldtime)\n",
    "# evaluate model\n",
    "oldtime = time.time()\n",
    "_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\n",
    "predictions = model.predict(testX)\n",
    "testMAE = np.absolute(np.subtract(testy,predictions[:,0])).mean()\n",
    "\n",
    "predictions = model.predict(X)\n",
    "totalMAE = np.absolute(np.subtract(y,predictions[:,0])).mean()\n",
    "\n",
    "print(\"Test, Total MAE:\", str(testMAE), str(totalMAE))\n",
    "print(\"testing time:\")\n",
    "print(time.time()-oldtime)\n",
    "model.summary()\n",
    "\n",
    "# Notes:\n",
    "#   - Flatte, Dense 100, rmsprop Test, Total MAE: 33.09671329490874 33.18895348192425\n",
    "#   - Flatten, Dense 100, adam, Test, Total MAE: 27.908568967205614 28.388384894643007\n",
    "#   - Flatten, Dense 50, then final neuron, Test, Total RMSE: 134.23943523918422 134.3048856681949\n",
    "#   - Just found out I had metrics wrong: Train error came down to 0.735 bpm\n",
    "#   - Test, Total MAE: 2.3047275488171093 1.3646295197764875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "print(predictions[:,0])\n",
    "# print(predictions[:,0]-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network still needs work before I can really scale it to use the entire dataset. Its too noisey even on its own data.\n",
    "fig = plt.figure(figsize=(40, 6))\n",
    "predictions = model.predict(X)\n",
    "# yhat = savgol_filter(predictions[:,0], 71, 3) # window size 51, polynomial order 3\n",
    "totalMAE = np.absolute(np.subtract(y,predictions[:,0])).mean()\n",
    "print(\"Test, Total MAE:\", str(testMAE), str(totalMAE))\n",
    "\n",
    "\n",
    "# aa=pd.DataFrame(predictions)\n",
    "# for i in range(50):\n",
    "#   plt.plot(predictions[:, i])\n",
    "# # plt.plot(y)\n",
    "plt.plot(predictions[:,0])\n",
    "plt.plot(y)\n",
    "# plt.plot(yhat)\n",
    "# X1MAE = np.absolute(np.subtract(y1,predictions)).mean()\n",
    "# plt.title(X1MAE)\n",
    "plt.show\n",
    "\n",
    "\n",
    "a = np.zeros(shape=(9999,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[:, 1].shape)\n",
    "plot_model(model, to_file = proj_dir + 'model_plot.png', show_shapes = True, show_layer_names=True)\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(x_train[0].shape)\n",
    "t = 1200\n",
    "plt.plot(X[t])\n",
    "plt.title(y[t])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
